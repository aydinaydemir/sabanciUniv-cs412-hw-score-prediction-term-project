{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "class TextAnalysis:\n",
    "    def __init__(self, data_path, scores_path, train_dataset_path):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.data_path = data_path\n",
    "        self.scores_path = scores_path\n",
    "        self.train_dataset_path = train_dataset_path\n",
    "        self.df, self.code2convos = self._load_and_process_data()\n",
    "        self.labeled_data_df, self.clf, self.vectorizer = self._train_naive_bayes_classifier()\n",
    "        self.models, self.evaluation = self._train_models_per_question()\n",
    "\n",
    "    def _remove_stopwords(self, tokens):\n",
    "        return [token for token in tokens if token.lower() not in self.stop_words]\n",
    "\n",
    "    def _load_and_process_data(self):\n",
    "        code2convos = dict()\n",
    "\n",
    "        pbar = tqdm.tqdm(sorted(list(glob(self.data_path))))\n",
    "        for path in pbar:\n",
    "            # print(Path.cwd() / path)\n",
    "            file_code = os.path.basename(path).split(\".\")[0]\n",
    "            with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "                    \n",
    "                # get the file id to use it as key later on\n",
    "                fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "                # read the html file\n",
    "                html_page = fh.read()\n",
    "\n",
    "                # parse the html file with bs4 so we can extract needed stuff\n",
    "                soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "                # grab the conversations with the data-testid pattern\n",
    "                data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "                conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "                convo_texts = []\n",
    "\n",
    "                for i, convo in enumerate(conversations):\n",
    "                    convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "                    if len(convo) > 0:\n",
    "                        role = convo[0].get(\"data-message-author-role\")\n",
    "                        convo_texts.append({\n",
    "                                \"role\" : role,\n",
    "                                \"text\" : convo[0].text\n",
    "                            }\n",
    "                        )\n",
    "                        \n",
    "                code2convos[file_code] = convo_texts\n",
    "\n",
    "        prompts = []\n",
    "        answers = []\n",
    "        code2prompts = defaultdict(list)\n",
    "        code2answers = defaultdict(list)\n",
    "        for code , convos in code2convos.items():\n",
    "            user_prompts = []\n",
    "            for conv in convos:\n",
    "                if conv[\"role\"] == \"user\":\n",
    "                    prompts.append(conv[\"text\"].lower())\n",
    "                    user_prompts.append(conv[\"text\"].lower()) # Adding the lower case version of the prompt\n",
    "                else:\n",
    "                    answers.append(conv[\"text\"].lower())\n",
    "                    code2answers[code].append(conv[\"text\"].lower()) # Adding the lower case version of the answer\n",
    "\n",
    "            code2prompts[code] = user_prompts\n",
    "\n",
    "\n",
    "        # mapping prompts to answers\n",
    "        code2prompt_answer_pairs = defaultdict(list)\n",
    "\n",
    "        for code in code2convos:\n",
    "            for prompt, answer in zip(code2prompts[code], code2answers[code]):\n",
    "                code2prompt_answer_pairs[code].append((prompt, answer))\n",
    "\n",
    "\n",
    "        code2prompt_answer_pairs[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"][0]\n",
    "\n",
    "        # Converting the dictionary to a DataFrame\n",
    "        refactored_data = []\n",
    "        for code, pairs in code2prompt_answer_pairs.items():\n",
    "            vectorized_pairs = [(prompt.split(), answer.split()) for prompt, answer in pairs]\n",
    "            refactored_data.append({'code': code, 'prompt_answer_pairs': vectorized_pairs})\n",
    "\n",
    "        df = pd.DataFrame(refactored_data)\n",
    "\n",
    "\n",
    "        # reading the scores\n",
    "        scores = pd.read_csv(\"data/scores.csv\", sep=\",\")\n",
    "        scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "        # selecting the columns we need and we care\n",
    "        scores = scores[[\"code\", \"grade\"]]\n",
    "\n",
    "        # join the scores with the df\n",
    "        df = df.merge(scores, on=\"code\")\n",
    "        df = df.sort_values(by=[\"grade\"], ascending=False)\n",
    "\n",
    "\n",
    "        return df, code2convos\n",
    "\n",
    "    def _train_naive_bayes_classifier(self):\n",
    "        labeled_data_df = pd.read_csv(self.train_dataset_path, sep=\"\\t\")\n",
    "        labeled_data_df['prompt'] = labeled_data_df['prompt'].str.lower()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            labeled_data_df['prompt'],\n",
    "            labeled_data_df['related_question'],\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train = vectorizer.fit_transform(X_train)\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        return labeled_data_df, clf, vectorizer\n",
    "    \n",
    "    def _train_models_per_question(self):\n",
    "        new_df = pd.DataFrame(columns=[\"prompt\", \"which_question\", \"grade\"])\n",
    "\n",
    "        for row in self.df.itertuples():\n",
    "            for prompt, answer in row.prompt_answer_pairs:\n",
    "                #removing stop words\n",
    "                prompt = self._remove_stopwords(prompt)\n",
    "                #convert prompt to string\n",
    "                promptStr = \" \".join(prompt)\n",
    "                #add it to a new a new df without using append\n",
    "                qNo = self._predict_question_number(promptStr)\n",
    "\n",
    "                new_df.loc[len(new_df.index)] = [promptStr, qNo, row.grade]\n",
    "\n",
    "\n",
    "        # replace Nan values with the mean of the column for column grade\n",
    "        new_df[\"grade\"].fillna((new_df[\"grade\"].mean()), inplace=True)\n",
    "        self.df = new_df.copy()\n",
    "\n",
    "\n",
    "        models = {}\n",
    "        evaluation = {}\n",
    "        for question_number in new_df['which_question'].unique():\n",
    "            question_data = new_df[new_df['which_question'] == question_number]\n",
    "            X = question_data['prompt']\n",
    "            y = question_data['grade']\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            pipeline = make_pipeline(TfidfVectorizer(), LinearRegression())\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            models[question_number] = pipeline\n",
    "            evaluation[question_number] = {'MSE': mse, 'R2': r2}\n",
    "\n",
    "        return models, evaluation\n",
    "    \n",
    "    def _predict_question_number(self, prompt):\n",
    "        prompt_vect = self.vectorizer.transform([prompt.lower()])\n",
    "        return self.clf.predict(prompt_vect)[0]\n",
    "    \n",
    "\n",
    "    def predict_with_similarity_adjustment(self, prompt):\n",
    "        prompt = self._remove_stopwords(prompt.split())\n",
    "        prompt = \" \".join(prompt)\n",
    "        question_number = self._predict_question_number(prompt)\n",
    "        pipeline = self.models.get(question_number)\n",
    "        if not pipeline:\n",
    "            raise ValueError(f\"No model found for question number {question_number}.\")\n",
    "        vectorizer = pipeline.named_steps['tfidfvectorizer']\n",
    "        model = pipeline.named_steps['linearregression']\n",
    "        prompt_vector = vectorizer.transform([prompt])\n",
    "        train_vectors = vectorizer.transform(self.df[self.df['which_question'] == question_number]['prompt'])\n",
    "        similarities = cosine_similarity(prompt_vector, train_vectors)\n",
    "        max_similarity = np.max(similarities)\n",
    "        predicted_score = model.predict(prompt_vector)[0]\n",
    "        adjusted_score = predicted_score * max_similarity\n",
    "        return adjusted_score, max_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:05<00:00, 21.80it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ta = TextAnalysis(\"data/html/*.html\", \"data/scores.csv\", \"data/labeled_data/train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello! i want to make your help on my homework about machine learning with python usage. we will go section by section firstly i want to read a csv file with the pandas library in the given path /content/cs412_hw1_dataset.csv ', 'i think you understood me wrong. i want you to generate a code that read a csv file with pandas library in the given path /content/cs412_hw1_dataset.csv', 'now lets understand this data set. first we need to find the shape of the dataset with shape function. then we have to display variable names(both dependent and independent). then we have to display the summary of dataset with info function.  finally, display the first 5 rows from training dataset. (hint: you can use the head function)', 'now lets go for another. i want to check if there any missing values in my dataset. if there is i want to fill them with the most common value technuqiue. after that i want to encode categorical labels with the mappings given in the cell below. (hint: you can use map function)\\n\\nhere is mapping: \\n\\nsex_map = {\\'female\\':1, \\'male\\': 0}\\n\\nisland_map = {\\'biscoe\\': 1,\\n              \\'dream\\': 2,\\n              \\'torgensen\\': 3}\\n\\ndiet_map = {\\'fish\\': 1,\\n              \\'krill\\': 2,\\n              \\'squid\\': 3,\\n            \"parental\":4}\\n\\nlife_stage_map = {\\'chick\\': 1,\\n              \\'juvenile\\': 2,\\n              \\'adult\\': 3}\\n\\nhealth_metrics_map = {\\'healthy\\': 1,\\n              \\'overweight\\': 2,\\n              \\'underweight\\': 3}', 'now lets go for another section. i want you to shuffle the dataset and seperate your dependent variable as x and independent variable as y. the column health_metrics is y, the rest is x. then split training and test sets as 80% and 20%, respectively.', \"now lets focus on:\\n\\ncalculate the correlations for all features in dataset. highlight any strong correlations with the target variable. plot your results in a heatmap.\\n\\nthen:\\nselect a subset of features that are likely strong predictors, justifying your choices based on the computed correlations.\\n\\nfinally:\\npropose two hypothetical features that could enhance the model's predictive accuracy for y, explaining how they might be derived and their expected impact. show the resulting correlations with target variable.\\n\\ngenerate a python code according to this\", 'i created my heatmap and i saw that flipper_length_mm and body_mass_g are highly correlated what should i do now? ', 'okay now lets go for another step. \\n\\nchoose 2 hyperparameters to tune. you can use the (https://scikit-learn.org/stable/modules/generated/sklearn.tree.decisiontreeclassifier.html) for the available hyperparameters *(hyperparameters are listed under \"parameters\" in the documentation)*. \\nuse gridsearchcv for hyperparameter tuning, with a cross-validation value of 5. use validation accuracy to pick the best hyper-parameter values. \\nexplain the hyperparameters you chose to tune. (what are the hyperparameters you chose? why did you choose them?)', 'can we also print accuracy score', 'okay now we \\n- re-train model with the hyperparameters you have chosen.\\n- plot the tree you have trained. \\n\\nhint: you can import the **plot_tree** function from the sklearn library.', \"i write a pipeline before that since my data includes some string columns\\n preprocessor = columntransformer(transformers=[\\n    ('species', onehotencoder(), ['species'])\\n], remainder='passthrough')\\n\\npipeline = pipeline(steps=[\\n    ('preprocessor', preprocessor),\\n    ('classifier', decisiontreeclassifier(max_depth=best_params['classifier__max_depth'], \\n                                          min_samples_split=best_params['classifier__min_samples_split']))\\n])\\n\\npipeline.fit(x_train, y_train)\\n\\nthen \\n\\nplt.figure(figsize=(20,10))\\ntree_plot = plot_tree(pipeline.named_steps['classifier'], filled=true, feature_names=pipeline.named_steps['preprocessor'].transformers_[0][1].get_feature_names_out().tolist() + x_train.columns.tolist(), class_names=true, rounded=true, fontsize=12)\\nplt.show()\\n\\njust want you to be aware it for further steps\", 'now its time to do:\\n\\n- predict the labels of testing data using the tree you have trained. \\n- report the classification accuracy. \\n- plot & investigate the confusion matrix. fill the following blanks.\\n> the model most frequently mistakes class(es) _________ for class(es) _________.\\n\\nhint: you can use the confusion_matrix function from sklearn.metrics', 'and the last step! now its time to find the information gain on the first split with entropy according to the formula from the lecture notes:\\ninformation gain= entropy(parent) - [average entropy(children)]', \"now instead of use pipeline i used:\\nlabel_encoder = labelencoder()\\n\\n\\ndf['species'] = label_encoder.fit_transform(df['species'])\\n\\nnow i want to make this step again \\n\\n- predict the labels of testing data using the tree you have trained in step 6. (10 pts)\\n- report the classification accuracy. (2 pts)\\n- plot & investigate the confusion matrix. fill the following blanks. (8 pts)\\n> the model most frequently mistakes class(es) _________ for class(es) _________.\\n\\nhint: you can use the confusion_matrix function from sklearn.metrics\", 'now can we make the information gain? how can i do it please generate a python code']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_prompts_from_html(file_name, data_path=\"data/html\"):\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return []\n",
    "    \n",
    "    code2convos = dict()\n",
    "    prompts = []\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"latin1\") as fh:\n",
    "        # Extract file code\n",
    "        file_code = os.path.basename(file_path).split(\".\")[0]\n",
    "\n",
    "        # Read and parse the HTML file\n",
    "        html_page = fh.read()\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        # Pattern to identify conversation elements\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "        convo_texts = []\n",
    "        for convo in conversations:\n",
    "            # Extract messages from the conversation\n",
    "            msgs = convo.find_all(\"div\", attrs={\"data-message-author-role\": re.compile(r\"(user|assistant)\")})\n",
    "            for msg in msgs:\n",
    "                role = msg.get(\"data-message-author-role\")\n",
    "                convo_texts.append({\"role\": role, \"text\": msg.text})\n",
    "\n",
    "        # Store conversations\n",
    "        code2convos[file_code] = convo_texts\n",
    "\n",
    "    # Separating prompts and answers\n",
    "    for code, convos in code2convos.items():\n",
    "        for conv in convos:\n",
    "            if conv[\"role\"] == \"user\":\n",
    "                prompts.append(conv[\"text\"].lower())\n",
    "\n",
    "    return prompts\n",
    "\n",
    "# Example usage\n",
    "file_name = \"0c95c563-f1e1-4a35-844c-2e8ccdd1b161.html\"\n",
    "prompts = extract_prompts_from_html(file_name)\n",
    "print(prompts)  # This will print the list of prompts extracted from the specified HTML file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Grade: 86.63078508164214\n",
      "Real Grade 0c95c563-f1e1-4a35-844c-2e8ccdd1b161.html: 96.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(86.63078508164214, 96.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def print_predicted_and_real_grade(html_file_name, ta, scores_file_path=\"data/scores.csv\"):\n",
    "    # Assuming ta is your instance of TextAnalysis\n",
    "    question_weights = {\n",
    "        'Q1': 0.05, 'Q2': 0.15, 'Q3': 0.05, 'Q4': 0.1,\n",
    "        'Q5': 0.2, 'Q6': 0.15, 'Q7': 0.2, 'Q8': 0.1\n",
    "    }\n",
    "\n",
    "    # Extract prompts from HTML file\n",
    "    prompts = extract_prompts_from_html(html_file_name)\n",
    "\n",
    "    # Calculate predicted score\n",
    "    question_scores = defaultdict(list)\n",
    "    for prompt in prompts:\n",
    "        predicted_score, max_similarity = ta.predict_with_similarity_adjustment(prompt)\n",
    "        question_number = ta._predict_question_number(prompt)\n",
    "        weighted_score = predicted_score * question_weights.get(f'Q{question_number}', 1)\n",
    "        question_scores[question_number].append(weighted_score)\n",
    "\n",
    "    total_score = 0\n",
    "    for question, scores in question_scores.items():\n",
    "        if scores:\n",
    "            average_score = sum(scores) / len(scores)\n",
    "            total_score += average_score\n",
    "\n",
    "    print(\"Predicted Grade:\", total_score)\n",
    "\n",
    "    # Extract the code from the HTML file name\n",
    "    file_code = html_file_name.split(\".\")[0]\n",
    "\n",
    "    # Read the scores.csv file\n",
    "    scores_df = pd.read_csv(scores_file_path)\n",
    "\n",
    "    # Find the grade for the extracted code\n",
    "    grade_row = scores_df[scores_df['code'] == file_code]\n",
    "\n",
    "    # Print the real grade\n",
    "    if not grade_row.empty:\n",
    "        grade = grade_row['grade'].iloc[0]\n",
    "        print(f\"Real Grade {html_file_name}: {grade}\")\n",
    "    else:\n",
    "        print(f\"No grade found for {html_file_name}\")\n",
    "\n",
    "    return total_score, grade if not grade_row.empty else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "html_file_name = \"0c95c563-f1e1-4a35-844c-2e8ccdd1b161.html\"\n",
    "print_predicted_and_real_grade(html_file_name, ta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Grade: 76.4669752495959\n",
      "Real Grade b73f91f8-732f-4a48-bcbd-eadbbb457a94.html: 94.0\n",
      "Predicted Grade: 9.900023451604111\n",
      "Real Grade 746b8f06-1e89-43b8-b73c-1121eecfc854.html: 99.0\n",
      "Predicted Grade: 88.6175622210682\n",
      "Real Grade 30283b91-7fc3-4125-985b-b441f0f489d6.html: 99.0\n",
      "Predicted Grade: 83.26034546519537\n",
      "Real Grade ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9.html: 85.0\n",
      "Predicted Grade: 84.01149667465069\n",
      "Real Grade 106ffe99-c787-4d09-9076-4ba411eb68b1.html: 84.0\n",
      "Predicted Grade: 33.881987932880534\n",
      "Real Grade 65ea56c3-e205-4ed9-8b85-bd1876228cee.html: 84.0\n",
      "Predicted Grade: 86.63078508164214\n",
      "Real Grade 0c95c563-f1e1-4a35-844c-2e8ccdd1b161.html: 96.0\n",
      "Predicted Grade: 89.76624111496253\n",
      "Real Grade 22bb7162-3399-464a-b30b-cf1fc3210b4e.html: 96.0\n",
      "Predicted Grade: 83.86547888269939\n",
      "Real Grade ba18e4e8-2c26-46d4-ba31-cc21947aabd5.html: 100.0\n",
      "Predicted Grade: 34.054266531352\n",
      "Real Grade 2446216c-c557-4ee8-b470-7e2ae3c88968.html: 98.0\n",
      "Predicted Grade: 91.19638823113763\n",
      "Real Grade 8a84e6e5-d200-4cc2-a288-5c81201100c7.html: 94.0\n",
      "Predicted Grade: 91.84401181937616\n",
      "Real Grade a948a3e5-70e5-447a-b3b4-baf3661f7b7e.html: 99.0\n",
      "Predicted Grade: 88.81468981263443\n",
      "Real Grade ebe86296-3cae-429a-9a7c-aa8f21cfd7cb.html: 90.0\n",
      "Predicted Grade: 93.25410594714104\n",
      "Real Grade 26d95379-e2f1-454c-a9d2-60cd80bc06a5.html: 100.0\n",
      "Predicted Grade: 69.68339376892796\n",
      "Real Grade 7c734c12-e18b-4de8-9004-c2523878db31.html: 86.0\n",
      "Predicted Grade: 75.09427897934093\n",
      "Real Grade 27de4332-d81f-47a2-b2a9-c0b023a30919.html: 100.0\n",
      "Predicted Grade: 90.31612882603874\n",
      "Real Grade 81fdeb2a-e7e5-4a05-8058-d31ea579b0d9.html: 94.0\n",
      "Predicted Grade: 0\n",
      "Real Grade b0640e51-6879-40cb-a4f5-329f952ef99d.html: 98.0\n",
      "Predicted Grade: 84.56721578446468\n",
      "Real Grade b13a2e11-1f0a-4f1e-9735-5f0674713593.html: 88.0\n",
      "Predicted Grade: 91.95198646280939\n",
      "Real Grade 45d2c21a-828e-46d9-8fcd-a4a39888773c.html: 98.0\n",
      "Predicted Grade: 80.32919906523361\n",
      "Real Grade 090d6217-5d69-4929-a342-19abab78324f.html: 84.0\n",
      "Predicted Grade: 0\n",
      "Real Grade 139235c7-736c-4237-92f0-92e8c116832c.html: 86.0\n",
      "Predicted Grade: 87.20657503531372\n",
      "Real Grade e779a2d6-6e4e-4ade-8a30-d624166c2ab3.html: 82.0\n",
      "Predicted Grade: 89.85154318599663\n",
      "Real Grade 663f8b4e-b683-4365-8316-b1dd1d325110.html: 99.0\n",
      "Predicted Grade: 83.33403932834796\n",
      "Real Grade 0f0c953a-a472-47c1-809b-9fc14dba9091.html: 83.0\n",
      "Predicted Grade: 91.50475448481335\n",
      "Real Grade 0225686d-b825-4cac-8691-3a3a5343df2b.html: 99.0\n",
      "Predicted Grade: 92.21980106938722\n",
      "Real Grade dfe46143-c07c-4bb6-bddc-7458995dba2f.html: 98.0\n",
      "Predicted Grade: 89.8424900154683\n",
      "Real Grade ab775974-7ddb-4a60-aef2-4655d7bb746d.html: 95.0\n",
      "Predicted Grade: 92.9722568832025\n",
      "Real Grade 223ae726-cb25-49df-a125-c4af3519c8e8.html: 100.0\n",
      "Predicted Grade: 94.22127733275543\n",
      "Real Grade 7b0ecddc-caa5-4b81-88ea-cd65a7270900.html: 100.0\n",
      "Predicted Grade: 84.92027699222444\n",
      "Real Grade 8505dcd7-9a9e-4ac3-b708-d3ffea7e6bb8.html: 95.0\n",
      "Predicted Grade: 88.34352474154346\n",
      "Real Grade b61f3f4c-785e-4d7c-b963-4480ece4656f.html: 93.0\n",
      "Predicted Grade: 0\n",
      "Real Grade 668ad17e-0240-49f7-b5a7-d22e502554c6.html: 99.0\n",
      "Predicted Grade: 88.75114484234756\n",
      "Real Grade 41b82427-7ae2-4c55-b8a3-310bb4abada0.html: 94.0\n",
      "Predicted Grade: 94.86917688418393\n",
      "Real Grade 941a3ef2-7559-430c-8682-830a04a6864c.html: 99.0\n",
      "Predicted Grade: 91.33234702616643\n",
      "Real Grade 17bd62e7-6792-4399-a573-07456a73901b.html: 100.0\n",
      "Predicted Grade: 93.6199590652201\n",
      "Real Grade 5541316f-6fbd-4441-b513-ac252e6355ec.html: 100.0\n",
      "Predicted Grade: 94.07666670677607\n",
      "Real Grade c21be348-17bd-4fdd-88f5-137f6a13cdee.html: 100.0\n",
      "Predicted Grade: 89.61122050136301\n",
      "Real Grade e76b910b-3156-4801-a73e-ddb16c763d43.html: 95.0\n",
      "Predicted Grade: 74.75619875657789\n",
      "Real Grade 97f57cf9-4f02-4f8c-b65c-8ea0009a82a2.html: 100.0\n",
      "Predicted Grade: 91.35274411149793\n",
      "Real Grade 04f91058-d0f8-4324-83b2-19c671f433dc.html: 97.0\n",
      "Predicted Grade: 91.55772563638105\n",
      "Real Grade a8270e39-5d70-4f1a-b031-6b4fcc55de01.html: 95.0\n",
      "Predicted Grade: 90.94529888934355\n",
      "Real Grade 69426dc0-b745-4f89-9c9a-943828d19db9.html: 99.0\n",
      "Predicted Grade: 82.17329303832265\n",
      "Real Grade adb31914-fa31-471d-b476-6111c393ec42.html: 85.0\n",
      "Predicted Grade: 84.81901551771159\n",
      "Real Grade db921a07-c234-41c6-8891-ef1b8a22a2f5.html: 96.0\n",
      "Predicted Grade: 90.2984216268512\n",
      "Real Grade f8ec3336-fd48-4654-ad98-62ccfb96d096.html: 100.0\n",
      "Predicted Grade: 58.93331313073035\n",
      "Real Grade 14ce054d-4619-4685-ba9b-4b5cd6f81b2d.html: 97.0\n",
      "Predicted Grade: 87.5377594872093\n",
      "Real Grade 331a45a0-341c-4faf-97de-75c82b31b61f.html: 93.0\n",
      "Predicted Grade: 91.82473200128436\n",
      "Real Grade b47559b3-3b5f-4958-bfa5-ec9f7a36aec0.html: 98.0\n",
      "Predicted Grade: 66.08082594266112\n",
      "Real Grade e8fd2278-1620-432d-81cb-02cac8543456.html: 15.0\n",
      "Predicted Grade: 93.16613223550664\n",
      "Real Grade 36bab6e3-0d16-4626-846b-33c0384f0c79.html: 100.0\n",
      "Predicted Grade: 89.80580832797112\n",
      "Real Grade 745bb746-6467-4146-8ef5-55f3ee3f589e.html: 100.0\n",
      "Predicted Grade: 53.37902664303583\n",
      "Real Grade 0ddfae9c-0dbd-4fbe-9e68-c3e0cb73b8fc.html: 80.0\n",
      "Predicted Grade: 85.34562034204959\n",
      "Real Grade aa15f751-f65f-4397-b138-df7b8301a12f.html: 93.0\n",
      "Predicted Grade: 78.87715970912949\n",
      "Real Grade 7af13aaa-dd6a-4850-856d-73ea55d0c2ff.html: 99.0\n",
      "Predicted Grade: 78.862041077491\n",
      "Real Grade 50a71154-2269-460c-9341-291221c6ef02.html: 84.0\n",
      "Predicted Grade: 85.59501399075805\n",
      "Real Grade 4fb21782-81f0-47c1-8831-58a748904a2c.html: 84.0\n",
      "Predicted Grade: 87.95573527410018\n",
      "Real Grade 0e466794-f7f8-4cc2-b07e-070b13a0b5e1.html: 89.0\n",
      "Predicted Grade: 90.11416269597503\n",
      "Real Grade 7ac3f7a5-bdbb-470c-a1b3-03da5887a408.html: 97.0\n",
      "Predicted Grade: 37.570741193006455\n",
      "Real Grade 0031c86e-81f4-4eef-9e0e-28037abf9883.html: 48.0\n",
      "Predicted Grade: 92.65535905047551\n",
      "Real Grade 089eb66d-4c3a-4f58-b98f-a3774a2efb34.html: 100.0\n",
      "Predicted Grade: 60.20007373198354\n",
      "Real Grade 6b4e988c-eead-46ff-a35b-b2fd325b2698.html: 78.0\n",
      "Predicted Grade: 35.83623921924077\n",
      "Real Grade 38296004-7336-4797-9db4-662a48309a1c.html: 98.0\n",
      "Predicted Grade: 90.53938516112106\n",
      "Real Grade 854397cb-a264-4bad-b30f-a9c1ba012511.html: 95.0\n",
      "Predicted Grade: 68.51584261513636\n",
      "Real Grade cc9ecae2-a3bf-43df-9628-56f587f400be.html: 94.0\n",
      "Predicted Grade: 91.2627236744654\n",
      "Real Grade 152a7787-ecd1-448f-a98e-8af0826d8215.html: 99.0\n",
      "Predicted Grade: 94.30623339491024\n",
      "Real Grade f2f18684-4a16-4c05-a2d1-c0f96d1de869.html: 100.0\n",
      "Predicted Grade: 93.07014183955143\n",
      "Real Grade fb8de815-224c-4d06-9fd4-7156d1a9920d.html: 98.0\n",
      "Predicted Grade: 67.54510120883651\n",
      "Real Grade 745ffa9e-f540-488a-b752-a3add11cb30b.html: 73.0\n",
      "Predicted Grade: 93.760744259858\n",
      "Real Grade c91d6fef-baf5-4e77-8bfc-b14fb7fc770d.html: 100.0\n",
      "Predicted Grade: 68.99352388056735\n",
      "Real Grade 6de08d44-bb5b-491d-a11e-51caa1eccd0c.html: 90.0\n",
      "Predicted Grade: 44.90362647464064\n",
      "Real Grade 42980d53-7bcd-4a36-bf3a-aa43f7417ac5.html: 71.0\n",
      "Predicted Grade: 57.32606066813818\n",
      "Real Grade 6312a21b-c6be-44f9-ad81-46307b339fb6.html: 75.0\n",
      "Predicted Grade: 93.61730468051363\n",
      "Real Grade 1038cb22-8ad2-4030-b44a-59f10352e91c.html: 100.0\n",
      "Predicted Grade: 87.16435016897819\n",
      "Real Grade f24219d6-07f0-4baf-80ac-18475dc5b66f.html: 93.0\n",
      "Predicted Grade: 87.38135073217725\n",
      "Real Grade 6c37a2d7-f786-4fc2-ba7a-04c3f961a365.html: 89.0\n",
      "Predicted Grade: 89.42738655035\n",
      "Real Grade 271b130d-50bd-436e-add6-38d9c618be8a.html: 97.0\n",
      "Predicted Grade: 76.46701442568609\n",
      "Real Grade 76a73730-6432-4f30-bb59-7a609bc9ba43.html: 99.0\n",
      "Predicted Grade: 82.01007429280415\n",
      "Real Grade 67c4a788-ec23-48c4-b6db-d76be6e118d6.html: 86.0\n",
      "Predicted Grade: 89.76764942592223\n",
      "Real Grade 24f01035-0717-4256-9952-c415aa8ecd10.html: 95.0\n",
      "Predicted Grade: 85.81078471675744\n",
      "Real Grade 3104d903-6012-484c-bd00-b93594b289ea.html: 87.0\n",
      "Predicted Grade: 47.65938251937099\n",
      "Real Grade e469cc3a-40fc-44e1-a7b7-3b2fbe621a8b.html: 89.0\n",
      "Predicted Grade: 88.22533026006124\n",
      "Real Grade 4e6fdf20-96fa-4f62-bf55-5c4c695afebe.html: 94.0\n",
      "Predicted Grade: 90.32359742075012\n",
      "Real Grade 5dbf76be-6634-4d42-a87f-b62b7fa6ceae.html: 97.0\n",
      "Predicted Grade: 91.17571968332155\n",
      "Real Grade dc9d3dc4-de7d-44e0-916c-04c85f94012a.html: 95.0\n",
      "Predicted Grade: 72.05279481860846\n",
      "Real Grade da219169-aacb-48b8-abdc-e25f08ad029e.html: 51.0\n",
      "Predicted Grade: 94.2866552315011\n",
      "Real Grade 918f3066-0b5a-46dc-92b8-b4279f0cb26e.html: 99.0\n",
      "Predicted Grade: 86.10090312910145\n",
      "Real Grade d4ab3f85-fdfb-434b-9774-96d94fd15d69.html: 92.0\n",
      "Predicted Grade: 94.92817868719429\n",
      "Real Grade 51f35201-da77-4b6d-a455-99cc84195c5c.html: 100.0\n",
      "Predicted Grade: 81.86537072320698\n",
      "Real Grade 1b54e38b-3b1d-425e-835a-d1e0fb2694fc.html: 100.0\n",
      "Predicted Grade: 92.51859331122236\n",
      "Real Grade 43ff9786-2b47-425b-8bad-e274d9988a0e.html: 98.0\n",
      "Predicted Grade: 88.4553210342492\n",
      "Real Grade a1e834df-f4f6-4962-bcda-17f8aefc7f86.html: 98.0\n",
      "Predicted Grade: 37.95344097117132\n",
      "Real Grade 6a2003ad-a05a-41c9-9d48-e98491a90499.html: 90.0\n",
      "Predicted Grade: 83.09490498811779\n",
      "Real Grade 8121427e-e5b1-400b-8342-d5d1c865f1d7.html: 86.0\n",
      "Predicted Grade: 40.73278443712124\n",
      "Real Grade 041f950b-c013-409a-a642-cffff60b9d4b.html: 90.0\n",
      "Predicted Grade: 93.55635666156536\n",
      "Real Grade 530b4e58-756d-4627-ad08-65ba0457ad42.html: 97.0\n",
      "Predicted Grade: 58.77515816212659\n",
      "Real Grade 410d88de-2489-4a83-8dae-6bc01e8e9f78.html: 88.0\n",
      "Predicted Grade: 70.03653002628722\n",
      "Real Grade d846484d-9257-40b4-98b9-6854288e8add.html: 96.0\n",
      "Predicted Grade: 87.43105528908717\n",
      "Real Grade a014d72a-81ad-43a4-8a2c-8046b7666320.html: 91.0\n",
      "Predicted Grade: 88.47873292310106\n",
      "Real Grade 1029802d-1057-4e3e-b827-e8a9c2ded3b9.html: 94.0\n",
      "Predicted Grade: 94.07175753384118\n",
      "Real Grade 5a62a8ee-c67c-475e-bd85-cf6d83c90ea9.html: 100.0\n",
      "Predicted Grade: 93.4688793676578\n",
      "Real Grade a0132e5d-4e16-4600-b2a7-5b6cd68a8b6a.html: 99.0\n",
      "Predicted Grade: 86.51340396790276\n",
      "Real Grade d61b757d-88bc-4a33-a620-0d76712207c3.html: 92.0\n",
      "Predicted Grade: 82.4476653367651\n",
      "Real Grade 7421916d-a0b5-4f0b-ad47-25a0cbf1b239.html: 85.0\n",
      "Predicted Grade: 74.00351332416932\n",
      "Real Grade 79cf72c1-d3aa-4e09-8ff2-6a8ad51b22ef.html: 99.0\n",
      "Predicted Grade: 58.98495205649294\n",
      "Real Grade 597c7a93-6b16-4af9-9846-154599f596e1.html: 91.0\n",
      "Predicted Grade: 3.100002006074609\n",
      "Real Grade 5e481e20-f714-4f11-b941-0ef2fd5976d3.html: 31.0\n",
      "Predicted Grade: 91.65165543492847\n",
      "Real Grade dd898b12-b04b-404e-9b59-f846a162c177.html: 98.0\n",
      "Predicted Grade: 93.09448885378264\n",
      "Real Grade e264c424-a241-43f7-acca-9fbbf21dc1c6.html: 100.0\n",
      "Predicted Grade: 91.93169185907223\n",
      "Real Grade b57fe283-97a4-457f-a5d0-ef441650c968.html: 99.0\n",
      "Predicted Grade: 102.46225589611585\n",
      "Real Grade 58fcd378-aa29-4067-813c-bb4de525428e.html: 100.0\n",
      "Predicted Grade: 89.85806898061084\n",
      "Real Grade f852596d-fdca-45aa-9050-d4f76ce6a53c.html: 98.0\n",
      "Predicted Grade: 88.73697639469982\n",
      "Real Grade 450550b4-3bb9-4b12-a7fd-121ac4a36ea9.html: 95.0\n",
      "Predicted Grade: 44.69243575472983\n",
      "Real Grade c65a33f5-6acf-4ff1-86fe-6003f165d44e.html: 90.0\n",
      "Predicted Grade: 40.64459966526823\n",
      "Real Grade c0f51763-0c69-45fb-a4d7-6906d53db43d.html: 90.0\n",
      "Predicted Grade: 0\n",
      "Real Grade da6b70d5-29f6-491a-ad46-037c77067128.html: 95.0\n",
      "Predicted Grade: 93.41878256574245\n",
      "Real Grade 58bee29c-a749-463e-8d56-c4edf0815b3f.html: 100.0\n",
      "Predicted Grade: 70.72292225558719\n",
      "Real Grade b5fe7d4d-e4a5-4ebd-8058-069d6505eb01.html: 96.0\n",
      "Predicted Grade: 93.06922054592245\n",
      "Real Grade 6a903495-c5be-4263-b4dd-75e2bbc30434.html: 97.0\n",
      "Predicted Grade: 90.39265325541498\n",
      "Real Grade 53ad17d1-5eb2-4af6-9c38-3c90c05ee695.html: 96.0\n",
      "Predicted Grade: 84.73027870499592\n",
      "Real Grade 63216e9b-5d0b-4047-97ee-302495d61640.html: 86.0\n",
      "Predicted Grade: 96.53169162326832\n",
      "Real Grade 56c6f8dd-f37c-44d2-9820-9459aa34c8af.html: nan\n",
      "Predicted Grade: 84.94797681845264\n",
      "Real Grade 2b9cf078-c56b-4020-9197-cd9f7d4f909c.html: 94.0\n",
      "Predicted Grade: 49.31554074531968\n",
      "No grade found for a70ebc32-7ee1-456f-9fa1-bef302fb0e78.html\n",
      "Predicted Grade: 79.47468963353683\n",
      "Real Grade b24c3a33-2952-4ae4-9f2d-643d8fdbc600.html: 78.0\n",
      "Predicted Grade: 87.1312009350992\n",
      "Real Grade 6d5742c1-77c4-429c-8f6e-ef1262ca5557.html: 93.0\n",
      "Predicted Grade: 83.41444990260669\n",
      "Real Grade 8be8e839-6dd0-44e0-b039-170b5b77cf2a.html: 86.0\n",
      "MSE: 675.6822226879308, MAE: 15.578238511053447, R-squared: -3.494143788928083\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def evaluate_model(directory, ta):\n",
    "    predicted_grades = []\n",
    "    real_grades = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".html\"):\n",
    "            # Pass only the filename, not the full path\n",
    "            result = print_predicted_and_real_grade(filename, ta)\n",
    "\n",
    "            if result is not None:\n",
    "                predicted_grade, real_grade = result\n",
    "                if real_grade is not None:\n",
    "                    predicted_grades.append(predicted_grade)\n",
    "                    real_grades.append(real_grade)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    real_grades = [rg for rg, pg in zip(real_grades, predicted_grades) if not np.isnan(rg) and not np.isnan(pg)]\n",
    "    predicted_grades = [pg for rg, pg in zip(real_grades, predicted_grades) if not np.isnan(rg) and not np.isnan(pg)]\n",
    "                    \n",
    "    mse = mean_squared_error(real_grades, predicted_grades)\n",
    "    mae = mean_absolute_error(real_grades, predicted_grades)\n",
    "    r2 = r2_score(real_grades, predicted_grades)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "# Example usage\n",
    "directory = \"data/html\"\n",
    "\n",
    "\n",
    "\n",
    "mse, mae, r2 = evaluate_model(directory, ta)\n",
    "print(f\"MSE: {mse}, MAE: {mae}, R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score: 91.00029353181002 Max Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "new_prompt = 'Tune Hyperparameters'\n",
    "predicted_score, max_similarity = ta.predict_with_similarity_adjustment(new_prompt)\n",
    "print(\"Predicted Score:\", predicted_score, \"Max Similarity:\", max_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
