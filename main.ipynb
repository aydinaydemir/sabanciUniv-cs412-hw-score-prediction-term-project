{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import graphviz\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class QuestionModel:\n",
    "    def __init__(self, html_files_path, scores_file_path, prompt_question_label_file_path):\n",
    "        self.html_files_path = html_files_path\n",
    "        self.scores_file_path = scores_file_path\n",
    "        self.prompt_question_label_file_path = prompt_question_label_file_path\n",
    "    \n",
    "        self.models = {}\n",
    "        self.evaluation = {}\n",
    "        self.clf = None\n",
    "        self.vectorizer = None\n",
    "\n",
    "\n",
    "\n",
    "        code2convos = dict()\n",
    "        pbar = tqdm.tqdm(sorted(list(glob(self.html_files_path))))\n",
    "        for path in pbar:\n",
    "            # print(Path.cwd() / path)\n",
    "            file_code = os.path.basename(path).split(\".\")[0]\n",
    "            with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "                    \n",
    "                # get the file id to use it as key later on\n",
    "                fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "                # read the html file\n",
    "                html_page = fh.read()\n",
    "\n",
    "                # parse the html file with bs4 so we can extract needed stuff\n",
    "                soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "                # grab the conversations with the data-testid pattern\n",
    "                data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "                conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "                convo_texts = []\n",
    "\n",
    "                for i, convo in enumerate(conversations):\n",
    "                    convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "                    if len(convo) > 0:\n",
    "                        role = convo[0].get(\"data-message-author-role\")\n",
    "                        convo_texts.append({\n",
    "                                \"role\" : role,\n",
    "                                \"text\" : convo[0].text\n",
    "                            }\n",
    "                        )\n",
    "                        \n",
    "                code2convos[file_code] = convo_texts\n",
    "        \n",
    "\n",
    "        prompts = []\n",
    "        answers = []\n",
    "        code2prompts = defaultdict(list)\n",
    "        code2answers = defaultdict(list)\n",
    "        for code , convos in code2convos.items():\n",
    "            user_prompts = []\n",
    "            for conv in convos:\n",
    "                if conv[\"role\"] == \"user\":\n",
    "                    prompts.append(conv[\"text\"].lower())\n",
    "                    user_prompts.append(conv[\"text\"].lower()) # Adding the lower case version of the prompt\n",
    "                else:\n",
    "                    answers.append(conv[\"text\"].lower())\n",
    "                    code2answers[code].append(conv[\"text\"].lower()) # Adding the lower case version of the answer\n",
    "\n",
    "            code2prompts[code] = user_prompts\n",
    "        # mapping prompts to answers\n",
    "        code2prompt_answer_pairs = defaultdict(list)\n",
    "\n",
    "        for code in code2convos:\n",
    "            for prompt, answer in zip(code2prompts[code], code2answers[code]):\n",
    "                code2prompt_answer_pairs[code].append((prompt, answer))\n",
    "\n",
    "\n",
    "        # Converting the dictionary to a DataFrame\n",
    "        refactored_data = []\n",
    "        for code, pairs in code2prompt_answer_pairs.items():\n",
    "            vectorized_pairs = [(prompt.split(), answer.split()) for prompt, answer in pairs]\n",
    "            refactored_data.append({'code': code, 'prompt_answer_pairs': vectorized_pairs})\n",
    "\n",
    "        df = pd.DataFrame(refactored_data)\n",
    "\n",
    "        # reading the scores\n",
    "        scores = pd.read_csv(\"data/scores.csv\", sep=\",\")\n",
    "        scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "        # selecting the columns we need and we care\n",
    "        scores = scores[[\"code\", \"grade\"]]\n",
    "\n",
    "        # join the scores with the df\n",
    "        df = df.merge(scores, on=\"code\")\n",
    "\n",
    "        # adding a new column named chat_length and assign it to the size of the prompt_answer_pairs\n",
    "        df[\"chat_length\"] = df[\"prompt_answer_pairs\"].apply(lambda x: len(x))\n",
    "        #sort by grade\n",
    "        df = df.sort_values(by=[\"grade\"], ascending=False)\n",
    "\n",
    "        #init a new df from scratch\n",
    "        new_df = pd.DataFrame(columns=[\"prompt\", \"which_question\", \"grade\"])\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            for prompt, answer in row.prompt_answer_pairs:\n",
    "                #removing stop words\n",
    "                prompt = remove_stopwords(prompt)\n",
    "                #convert prompt to string\n",
    "                promptStr = \" \".join(prompt)\n",
    "                #add it to a new a new df without using append\n",
    "                qNo = predict_question_number(promptStr,clf,vectorizer)\n",
    "\n",
    "                new_df.loc[len(new_df.index)] = [promptStr, qNo, row.grade]\n",
    "\n",
    "\n",
    "        # replace Nan values with the mean of the column for column grade\n",
    "        new_df[\"grade\"].fillna((new_df[\"grade\"].mean()), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def train_classifier(self, df):\n",
    "        \"\"\"\n",
    "        Train a classifier to predict the question number based on the prompt.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df['prompt'].str.lower(),\n",
    "            df['related_question'],\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        X_train_vect = self.vectorizer.fit_transform(X_train)\n",
    "        X_test_vect = self.vectorizer.transform(X_test)\n",
    "\n",
    "        self.clf = MultinomialNB()\n",
    "        self.clf.fit(X_train_vect, y_train)\n",
    "\n",
    "        # Calculate and print the accuracy\n",
    "        y_pred = self.clf.predict(X_test_vect)\n",
    "        accuracy = accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
