{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:05<00:00, 21.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  related_question\n",
      "0  ## 2) load training dataset (5 pts)\\n\\n*  read...                 1\n",
      "1  ## 3) understanding the dataset & preprocessin...                 2\n",
      "2  set x & y, split data (5 pts)\\n\\n*   shuffle t...                 3\n",
      "3  features and correlations (10 pts)\\n\\n* correl...                 4\n",
      "4  tune hyperparameters (20 pts)\\n* choose 2 hype...                 5\n",
      "Accuracy:  1.0\n",
      "Predicted question number for the new prompt is: 6\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "\n",
    "data_path = \"data/html/*.html\"\n",
    "\n",
    "code2convos = dict()\n",
    "\n",
    "pbar = tqdm.tqdm(sorted(list(glob(data_path))))\n",
    "for path in pbar:\n",
    "    # print(Path.cwd() / path)\n",
    "    file_code = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "            \n",
    "        # get the file id to use it as key later on\n",
    "        fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "        # read the html file\n",
    "        html_page = fh.read()\n",
    "\n",
    "        # parse the html file with bs4 so we can extract needed stuff\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        # grab the conversations with the data-testid pattern\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "        convo_texts = []\n",
    "\n",
    "        for i, convo in enumerate(conversations):\n",
    "            convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "            if len(convo) > 0:\n",
    "                role = convo[0].get(\"data-message-author-role\")\n",
    "                convo_texts.append({\n",
    "                        \"role\" : role,\n",
    "                        \"text\" : convo[0].text\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        code2convos[file_code] = convo_texts\n",
    "\n",
    "prompts = []\n",
    "answers = []\n",
    "code2prompts = defaultdict(list)\n",
    "code2answers = defaultdict(list)\n",
    "for code , convos in code2convos.items():\n",
    "    user_prompts = []\n",
    "    for conv in convos:\n",
    "        if conv[\"role\"] == \"user\":\n",
    "            prompts.append(conv[\"text\"].lower())\n",
    "            user_prompts.append(conv[\"text\"].lower()) # Adding the lower case version of the prompt\n",
    "        else:\n",
    "            answers.append(conv[\"text\"].lower())\n",
    "            code2answers[code].append(conv[\"text\"].lower()) # Adding the lower case version of the answer\n",
    "\n",
    "    code2prompts[code] = user_prompts\n",
    "\n",
    "\n",
    "# mapping prompts to answers\n",
    "code2prompt_answer_pairs = defaultdict(list)\n",
    "\n",
    "for code in code2convos:\n",
    "    for prompt, answer in zip(code2prompts[code], code2answers[code]):\n",
    "        code2prompt_answer_pairs[code].append((prompt, answer))\n",
    "\n",
    "\n",
    "code2prompt_answer_pairs[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"][0]\n",
    "\n",
    "# Converting the dictionary to a DataFrame\n",
    "refactored_data = []\n",
    "for code, pairs in code2prompt_answer_pairs.items():\n",
    "    vectorized_pairs = [(prompt.split(), answer.split()) for prompt, answer in pairs]\n",
    "    refactored_data.append({'code': code, 'prompt_answer_pairs': vectorized_pairs})\n",
    "\n",
    "df = pd.DataFrame(refactored_data)\n",
    "\n",
    "\n",
    "# reading the scores\n",
    "scores = pd.read_csv(\"data/scores.csv\", sep=\",\")\n",
    "scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "# selecting the columns we need and we care\n",
    "scores = scores[[\"code\", \"grade\"]]\n",
    "\n",
    "# join the scores with the df\n",
    "df = df.merge(scores, on=\"code\")\n",
    "\n",
    "# adding a new column named chat_length and assign it to the size of the prompt_answer_pairs\n",
    "df[\"chat_length\"] = df[\"prompt_answer_pairs\"].apply(lambda x: len(x))\n",
    "#sort by grade\n",
    "df = df.sort_values(by=[\"grade\"], ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labeled_data_df = pd.read_csv(\"data/labeled_data/train_dataset.csv\", sep=\"\\t\")\n",
    "\n",
    "labeled_data_df['prompt'] = labeled_data_df['prompt'].str.lower()\n",
    "\n",
    "print(labeled_data_df.head())\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    labeled_data_df['prompt'],\n",
    "    labeled_data_df['related_question'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize the prompts\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "def predict_question_number(prompt, clf, vectorizer):\n",
    "    prompt_vect = vectorizer.transform([prompt.lower()])\n",
    "    return clf.predict(prompt_vect)[0]\n",
    "\n",
    "new_prompt = \"hi. need help machine learning class hw using palmer penguins dataset extended dataset kaggle. task build decision tree classifier.\"\n",
    "predicted_question_number = predict_question_number(new_prompt, clf, vectorizer)\n",
    "print(\"Predicted question number for the new prompt is:\", predicted_question_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>which_question</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi. need help machine learning class hw using ...</td>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great! go step step though. first, need unders...</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing percentage 7.7</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank you. filling null values encode categori...</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes, proceed set x &amp; y, split data. first need...</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  which_question  grade\n",
       "0  hi. need help machine learning class hw using ...               6  100.0\n",
       "1  great! go step step though. first, need unders...               2  100.0\n",
       "2                             missing percentage 7.7               2  100.0\n",
       "3  thank you. filling null values encode categori...               2  100.0\n",
       "4  yes, proceed set x & y, split data. first need...               3  100.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#init a new df from scratch\n",
    "new_df = pd.DataFrame(columns=[\"prompt\", \"which_question\", \"grade\"])\n",
    "\n",
    "for row in df.itertuples():\n",
    "    for prompt, answer in row.prompt_answer_pairs:\n",
    "        #removing stop words\n",
    "        prompt = remove_stopwords(prompt)\n",
    "        #convert prompt to string\n",
    "        promptStr = \" \".join(prompt)\n",
    "        #add it to a new a new df without using append\n",
    "        qNo = predict_question_number(promptStr,clf,vectorizer)\n",
    "\n",
    "        new_df.loc[len(new_df.index)] = [promptStr, qNo, row.grade]\n",
    "\n",
    "\n",
    "# replace Nan values with the mean of the column for column grade\n",
    "new_df[\"grade\"].fillna((new_df[\"grade\"].mean()), inplace=True)\n",
    "\n",
    "\n",
    "def train_models_per_question(new_df):\n",
    "    models = {}\n",
    "    evaluation = {}\n",
    "    for question_number in new_df['which_question'].unique():\n",
    "        # Segment the data by question number\n",
    "        question_data = new_df[new_df['which_question'] == question_number]\n",
    "\n",
    "        # Split the data into features and target\n",
    "        X = question_data['prompt']\n",
    "        y = question_data['grade']\n",
    "\n",
    "        # Split into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Create a text processing and regression pipeline\n",
    "        pipeline = make_pipeline(TfidfVectorizer(), LinearRegression())\n",
    "\n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Save the model and its evaluation\n",
    "        models[question_number] = pipeline\n",
    "        evaluation[question_number] = {'MSE': mse, 'R2': r2}\n",
    "\n",
    "    return models, evaluation\n",
    "\n",
    "models, evaluation = train_models_per_question(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted question number for the prompt is: 5\n",
      "predicted score is:  93.41453216100302\n"
     ]
    }
   ],
   "source": [
    "def predict_with_similarity_adjustment(prompt, question_number, models, new_df):\n",
    "    prompt = prompt.lower()\n",
    "    #removing the stopwordstrain_vectors\n",
    "    prompt = remove_stopwords(prompt.split())\n",
    "    #convert prompt to string\n",
    "    prompt = \" \".join(prompt)\n",
    "\n",
    "    # Retrieve the model pipeline for the given question number\n",
    "    pipeline = models.get(question_number)\n",
    "    if not pipeline:\n",
    "        raise ValueError(f\"No model found for question number {question_number}.\")\n",
    "\n",
    "    # Get the vectorizer from the pipeline\n",
    "    vectorizer = pipeline.named_steps['tfidfvectorizer']\n",
    "    model = pipeline.named_steps['linearregression']\n",
    "\n",
    "    # Transform the new prompt into TF-IDF vector\n",
    "    prompt_vector = vectorizer.transform([prompt])\n",
    "\n",
    "    # Transform the training data prompts into TF-IDF vectors\n",
    "    train_vectors = vectorizer.transform(new_df[new_df['which_question'] == question_number]['prompt'])\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = cosine_similarity(prompt_vector, train_vectors)\n",
    "    \n",
    "    # Find the maximum similarity score\n",
    "    max_similarity = np.max(similarities)\n",
    "\n",
    "    # Predict the score using the regression model\n",
    "    predicted_score = model.predict(prompt_vector)[0]\n",
    "\n",
    "    # Adjust the predicted score based on similarity\n",
    "    adjusted_score = predicted_score * max_similarity\n",
    "\n",
    "    return adjusted_score, max_similarity\n",
    "\n",
    "\n",
    "new_prompt = 'Tune Hyperparameters (20 pts)* Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters *(Hyperparameters are listed under \"Parameters\" in the documentation)*. Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)-Explain the hyperparameters you chose to tune. *(What are the hyperparameters you chose? Why did you choose them?)* (5 pts)'\n",
    "question_number = predict_question_number(new_prompt, clf, vectorizer)\n",
    "print(f'The predicted question number for the prompt is: {question_number}')\n",
    "\n",
    "predicted_score, max_similarity = predict_with_similarity_adjustment(new_prompt, question_number, models, new_df)\n",
    "print(\"predicted score is: \", predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TextAnalysisModel:\n",
    "    a = 1\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.models = {}\n",
    "        self.evaluation = {}\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.clf = MultinomialNB()\n",
    "        self.df = None\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "\n",
    "    def remove_stopwords(self, tokens):\n",
    "        return [token for token in tokens if token.lower() not in self.stop_words]\n",
    "    \n",
    "    def predict_question_number(prompt, clf, vectorizer):\n",
    "        prompt_vect = vectorizer.transform([prompt.lower()])\n",
    "        return clf.predict(prompt_vect)[0]\n",
    "    \n",
    "    def train_question_number_classifier(self, labeled_data_path):\n",
    "        labeled_data_df = pd.read_csv(labeled_data_path, sep=\"\\t\")\n",
    "\n",
    "        labeled_data_df['prompt'] = labeled_data_df['prompt'].str.lower()\n",
    "\n",
    "        print(labeled_data_df.head())\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            labeled_data_df['prompt'],\n",
    "            labeled_data_df['related_question'],\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Vectorize the prompts\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        X_train = self.vectorizer.fit_transform(X_train)\n",
    "        X_test = self.vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the test data\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy: \", accuracy)\n",
    "    \n",
    "    def insert_scores(self, scores_path):\n",
    "        scores = pd.read_csv(scores_path, sep=\",\")\n",
    "        scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "        # selecting the columns we need and we care\n",
    "        scores = scores[[\"code\", \"grade\"]]\n",
    "\n",
    "        # join the scores with the df\n",
    "        df = df.merge(scores, on=\"code\")\n",
    "        \n",
    "    \n",
    "    def read_html(self, html_files_path):\n",
    "        code2convos = dict()\n",
    "\n",
    "        pbar = tqdm.tqdm(sorted(list(glob(html_files_path))))\n",
    "        for path in pbar:\n",
    "            # print(Path.cwd() / path)\n",
    "            file_code = os.path.basename(path).split(\".\")[0]\n",
    "            with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "                    \n",
    "                # get the file id to use it as key later on\n",
    "                fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "                # read the html file\n",
    "                html_page = fh.read()\n",
    "\n",
    "                # parse the html file with bs4 so we can extract needed stuff\n",
    "                soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "                # grab the conversations with the data-testid pattern\n",
    "                data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "                conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "                convo_texts = []\n",
    "\n",
    "                for i, convo in enumerate(conversations):\n",
    "                    convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "                    if len(convo) > 0:\n",
    "                        role = convo[0].get(\"data-message-author-role\")\n",
    "                        convo_texts.append({\n",
    "                                \"role\" : role,\n",
    "                                \"text\" : convo[0].text\n",
    "                            }\n",
    "                        )\n",
    "                        \n",
    "                code2convos[file_code] = convo_texts\n",
    "\n",
    "        prompts = []\n",
    "        answers = []\n",
    "        code2prompts = defaultdict(list)\n",
    "        code2answers = defaultdict(list)\n",
    "        for code , convos in code2convos.items():\n",
    "            user_prompts = []\n",
    "            for conv in convos:\n",
    "                if conv[\"role\"] == \"user\":\n",
    "                    prompts.append(conv[\"text\"].lower())\n",
    "                    user_prompts.append(conv[\"text\"].lower()) # Adding the lower case version of the prompt\n",
    "                else:\n",
    "                    answers.append(conv[\"text\"].lower())\n",
    "                    code2answers[code].append(conv[\"text\"].lower()) # Adding the lower case version of the answer\n",
    "\n",
    "            code2prompts[code] = user_prompts\n",
    "\n",
    "\n",
    "        # mapping prompts to answers\n",
    "        code2prompt_answer_pairs = defaultdict(list)\n",
    "\n",
    "        for code in code2convos:\n",
    "            for prompt, answer in zip(code2prompts[code], code2answers[code]):\n",
    "                code2prompt_answer_pairs[code].append((prompt, answer))\n",
    "\n",
    "\n",
    "        code2prompt_answer_pairs[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"][0]\n",
    "\n",
    "        # Converting the dictionary to a DataFrame\n",
    "        refactored_data = []\n",
    "        for code, pairs in code2prompt_answer_pairs.items():\n",
    "            vectorized_pairs = [(prompt.split(), answer.split()) for prompt, answer in pairs]\n",
    "            refactored_data.append({'code': code, 'prompt_answer_pairs': vectorized_pairs})\n",
    "\n",
    "        df = pd.DataFrame(refactored_data)\n",
    "\n",
    "\n",
    "        #init a new df from scratch\n",
    "        new_df = pd.DataFrame(columns=[\"prompt\", \"which_question\", \"grade\"])\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            for prompt, answer in row.prompt_answer_pairs:\n",
    "                #removing stop words\n",
    "                prompt = remove_stopwords(prompt)\n",
    "                #convert prompt to string\n",
    "                promptStr = \" \".join(prompt)\n",
    "                #add it to a new a new df without using append\n",
    "                qNo = self.predict_question_number(promptStr,self.clf,self.vectorizer)\n",
    "\n",
    "                new_df.loc[len(new_df.index)] = [promptStr, qNo, row.grade]\n",
    "\n",
    "\n",
    "        # replace Nan values with the mean of the column for column grade\n",
    "        new_df[\"grade\"].fillna((new_df[\"grade\"].mean()), inplace=True)\n",
    "        df = new_df.copy()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "model = TextAnalysisModel()\n",
    "model.load_and_preprocess_data(\"data/html/*.html\")\n",
    "model.train_text_classifier(\"data/labeled_data/train_dataset.csv\")\n",
    "\n",
    "# You can then use methods of the model object to perform specific actions, like:\n",
    "# model.predict_question_number(\"some prompt\")\n",
    "# model.predict_with_similarity_adjustment(\"some prompt\", question_number, new_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
