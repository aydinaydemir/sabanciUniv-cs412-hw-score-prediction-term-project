{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#\n",
    "\n",
    "class TextAnalysis:\n",
    "    def __init__(self, data_path, scores_path, train_dataset_path):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.data_path = data_path\n",
    "        self.scores_path = scores_path\n",
    "        self.train_dataset_path = train_dataset_path\n",
    "        self.df, self.code2prompts = self._load_and_process_data()\n",
    "        self.labeled_data_df, self.clf, self.vectorizer = self._train_naive_bayes_classifier()\n",
    "        self.models, self.evaluation = self._train_models_per_question()\n",
    "\n",
    "    def _remove_stopwords(self, tokens):\n",
    "        return [token for token in tokens if token.lower() not in self.stop_words]\n",
    "\n",
    "    def _load_and_process_data(self, data_path=None):\n",
    "        code2convos = dict()\n",
    "\n",
    "        pbar = tqdm.tqdm(sorted(list(glob(self.data_path))))\n",
    "        for path in pbar:\n",
    "            # print(Path.cwd() / path)\n",
    "            file_code = os.path.basename(path).split(\".\")[0]\n",
    "            with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "                    \n",
    "                # get the file id to use it as key later on\n",
    "                fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "                # read the html file\n",
    "                html_page = fh.read()\n",
    "\n",
    "                # parse the html file with bs4 so we can extract needed stuff\n",
    "                soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "                # grab the conversations with the data-testid pattern\n",
    "                data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "                conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "                convo_texts = []\n",
    "\n",
    "                for i, convo in enumerate(conversations):\n",
    "                    convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "                    if len(convo) > 0:\n",
    "                        role = convo[0].get(\"data-message-author-role\")\n",
    "                        convo_texts.append({\n",
    "                                \"role\" : role,\n",
    "                                \"text\" : convo[0].text\n",
    "                            }\n",
    "                        )\n",
    "                        \n",
    "                code2convos[file_code] = convo_texts\n",
    "\n",
    "        prompts = []\n",
    "        answers = []\n",
    "        code2prompts = dict()\n",
    "        code2answers = defaultdict(list)\n",
    "        for code , convos in code2convos.items():\n",
    "            user_prompts = []\n",
    "            for conv in convos:\n",
    "                if conv[\"role\"] == \"user\":\n",
    "                    prompts.append(conv[\"text\"].lower())\n",
    "                    user_prompts.append(conv[\"text\"].lower()) # Adding the lower case version of the prompt\n",
    "                else:\n",
    "                    answers.append(conv[\"text\"].lower())\n",
    "                    code2answers[code].append(conv[\"text\"].lower()) # Adding the lower case version of the answer\n",
    "\n",
    "            code2prompts[code] = user_prompts\n",
    "\n",
    "\n",
    "        # mapping prompts to answers\n",
    "        code2prompt_answer_pairs = defaultdict(list)\n",
    "\n",
    "        for code in code2convos:\n",
    "            for prompt, answer in zip(code2prompts[code], code2answers[code]):\n",
    "                code2prompt_answer_pairs[code].append((prompt, answer))\n",
    "\n",
    "\n",
    "        code2prompt_answer_pairs[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"][0]\n",
    "\n",
    "        # Converting the dictionary to a DataFrame\n",
    "        refactored_data = []\n",
    "        for code, pairs in code2prompt_answer_pairs.items():\n",
    "            vectorized_pairs = [(prompt.split(), answer.split()) for prompt, answer in pairs]\n",
    "            refactored_data.append({'code': code, 'prompt_answer_pairs': vectorized_pairs})\n",
    "\n",
    "        df = pd.DataFrame(refactored_data)\n",
    "\n",
    "        scores = self.give_codes2scores()\n",
    "        \n",
    "\n",
    "        # join the scores with the df\n",
    "        df = df.merge(scores, on=\"code\")\n",
    "        df = df.sort_values(by=[\"grade\"], ascending=False)\n",
    "\n",
    "\n",
    "        return df, code2prompts\n",
    "    \n",
    "    def give_codes2scores(self):\n",
    "        # reading the scores\n",
    "        scores = pd.read_csv(self.scores_path, sep=\",\")\n",
    "        scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "        scores = scores[[\"code\", \"grade\"]]\n",
    "        #drop na\n",
    "        scores.dropna(inplace=True)\n",
    "        return scores\n",
    "\n",
    "    def _train_naive_bayes_classifier(self):\n",
    "        labeled_data_df = pd.read_csv(self.train_dataset_path, sep=\"\\t\")\n",
    "        labeled_data_df['prompt'] = labeled_data_df['prompt'].str.lower()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            labeled_data_df['prompt'],\n",
    "            labeled_data_df['related_question'],\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train = vectorizer.fit_transform(X_train)\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        return labeled_data_df, clf, vectorizer\n",
    "    \n",
    "    def _train_models_per_question(self):\n",
    "        new_df = pd.DataFrame(columns=[\"prompt\", \"which_question\", \"grade\"])\n",
    "\n",
    "        for row in self.df.itertuples():\n",
    "            for prompt, answer in row.prompt_answer_pairs:\n",
    "                #removing stop words\n",
    "                prompt = self._remove_stopwords(prompt)\n",
    "                #convert prompt to string\n",
    "                promptStr = \" \".join(prompt)\n",
    "                #add it to a new a new df without using append\n",
    "                qNo = self._predict_question_number(promptStr)\n",
    "\n",
    "                new_df.loc[len(new_df.index)] = [promptStr, qNo, row.grade]\n",
    "\n",
    "\n",
    "        # replace Nan values with the mean of the column for column grade\n",
    "        new_df[\"grade\"].fillna((new_df[\"grade\"].mean()), inplace=True)\n",
    "        self.df = new_df.copy()\n",
    "\n",
    "\n",
    "        models = {}\n",
    "        evaluation = {}\n",
    "        for question_number in new_df['which_question'].unique():\n",
    "            question_data = new_df[new_df['which_question'] == question_number]\n",
    "            X = question_data['prompt']\n",
    "            y = question_data['grade']\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            pipeline = make_pipeline(TfidfVectorizer(), LinearRegression())\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            models[question_number] = pipeline\n",
    "            evaluation[question_number] = {'MSE': mse, 'R2': r2}\n",
    "\n",
    "        return models, evaluation\n",
    "    \n",
    "    def _predict_question_number(self, prompt):\n",
    "        prompt_vect = self.vectorizer.transform([prompt.lower()])\n",
    "        return self.clf.predict(prompt_vect)[0]\n",
    "    \n",
    "\n",
    "    def predict_with_similarity_adjustment(self, prompt):\n",
    "        prompt = self._remove_stopwords(prompt.split())\n",
    "        prompt = \" \".join(prompt)\n",
    "        question_number = self._predict_question_number(prompt)\n",
    "        pipeline = self.models.get(question_number)\n",
    "        if not pipeline:\n",
    "            raise ValueError(f\"No model found for question number {question_number}.\")\n",
    "        vectorizer = pipeline.named_steps['tfidfvectorizer']\n",
    "        model = pipeline.named_steps['linearregression']\n",
    "        prompt_vector = vectorizer.transform([prompt])\n",
    "        train_vectors = vectorizer.transform(self.df[self.df['which_question'] == question_number]['prompt'])\n",
    "        similarities = cosine_similarity(prompt_vector, train_vectors)\n",
    "        max_similarity = np.max(similarities)\n",
    "        predicted_score = model.predict(prompt_vector)[0]\n",
    "        adjusted_score = predicted_score * max_similarity\n",
    "        return adjusted_score, max_similarity\n",
    "    \n",
    "    def predict_grades_for_multiple_prompts(self, code, prompts):\n",
    "        question_weights = {\n",
    "            'Q1': 0.05, 'Q2': 0.15, 'Q3': 0.05, 'Q4': 0.1,\n",
    "            'Q5': 0.2, 'Q6': 0.15, 'Q7': 0.2, 'Q8': 0.1\n",
    "        }\n",
    "\n",
    "        question_scores = {\n",
    "            'Q1': [], 'Q2': [], 'Q3': [], 'Q4': [], 'Q5': [], 'Q6': [], 'Q7': [], 'Q8': [],\n",
    "        }\n",
    "\n",
    "        # Predict and store scores for each prompt\n",
    "        for prompt in prompts:\n",
    "            score, _ = self.predict_with_similarity_adjustment(prompt)\n",
    "            numeric_question_number = self._predict_question_number(prompt)\n",
    "            question_number = f'Q{numeric_question_number}'\n",
    "            question_scores[question_number].append(score)\n",
    "\n",
    "        \n",
    "\n",
    "        total_weighted_score = 0\n",
    "        total_weight =0\n",
    "\n",
    "        # Calculate weighted score for each question\n",
    "        for question, scores in question_scores.items():\n",
    "            if scores:\n",
    "                average_score = sum(scores) / len(scores)\n",
    "                question_weight = question_weights[question]\n",
    "                total_weight += question_weight\n",
    "                weighted_score = average_score * question_weight\n",
    "                total_weighted_score += weighted_score\n",
    "            #else:\n",
    "                #print(f\"No prompt for question {question}.\")\n",
    "                # Calculate average of other questions if no prompt for this question\n",
    "                #average_score = sum([sum(q_scores) / len(q_scores) for q_scores in question_scores.values() if (len(q_scores) > 1 )]) / len([q_scores for q_scores in question_scores.values() if (len(q_scores) > 1 )])\n",
    "        \n",
    "\n",
    "        if total_weight == 0:\n",
    "            print(\"HTML PAGE IS 404 FOR THE HTML CODE: \", code)\n",
    "            return -1\n",
    "        else:\n",
    "            unweighted_score = total_weighted_score / total_weight\n",
    "            total_weighted_score += (1-total_weight) * unweighted_score\n",
    "\n",
    "            \n",
    "\n",
    "        return total_weighted_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:06<00:00, 20.27it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ta = TextAnalysis(\"data/html/*.html\", \"data/scores.csv\", \"data/labeled_data/train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML PAGE IS 404 FOR THE HTML CODE:  139235c7-736c-4237-92f0-92e8c116832c\n",
      "Code 56c6f8dd-f37c-44d2-9820-9459aa34c8af not found in code2scores\n",
      "HTML PAGE IS 404 FOR THE HTML CODE:  668ad17e-0240-49f7-b5a7-d22e502554c6\n",
      "HTML PAGE IS 404 FOR THE HTML CODE:  b0640e51-6879-40cb-a4f5-329f952ef99d\n",
      "HTML PAGE IS 404 FOR THE HTML CODE:  da6b70d5-29f6-491a-ad46-037c77067128\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "There are  4  predictions with absolute difference greater than 10\n",
      "There are  122  entries that are predicted, the ones are not predicted are because of 404 html page or no labeled grades for the html code\n",
      "Mean Squared Error (MSE): 46.40771950767913\n",
      "Root Mean Squared Error (RMSE): 6.812321154179325\n",
      "Mean Absolute Error (MAE): 2.9489140918919707\n",
      "R-squared (R2): 0.696626685602723\n"
     ]
    }
   ],
   "source": [
    "code2promptsTemp = ta.code2prompts.copy()\n",
    "code2scores = ta.give_codes2scores().copy()\n",
    "actual_scores = []\n",
    "predicted_scores = []\n",
    "\n",
    "counter = 0\n",
    "for code, prompts in code2promptsTemp.items():\n",
    "    predicted_score = ta.predict_grades_for_multiple_prompts(code, prompts)\n",
    "    if (predicted_score != -1):\n",
    "        matching_row = code2scores[code2scores['code'] == code]\n",
    "        if not matching_row.empty:\n",
    "            actual_score = matching_row['grade'].iloc[0]\n",
    "            # Append the actual and predicted scores to their respective lists\n",
    "            actual_scores.append(actual_score)\n",
    "            predicted_scores.append(predicted_score)\n",
    "            #if absolute difference is greater than 10, print it\n",
    "            if abs(actual_score - predicted_score) > 10:\n",
    "                counter += 1\n",
    "                \n",
    "        else:\n",
    "            print(f\"Code {code} not found in code2scores\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"There are \", counter, \" predictions with absolute difference greater than 10\")\n",
    "print(\"There are \", len(actual_scores), \" entries that are predicted, the ones are not predicted are because of 404 html page or no labeled grades for the html code\")\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "mse = mean_squared_error(actual_scores, predicted_scores)\n",
    "rmse = mean_squared_error(actual_scores, predicted_scores, squared=False)\n",
    "mae = mean_absolute_error(actual_scores, predicted_scores)\n",
    "r2 = r2_score(actual_scores, predicted_scores)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R2): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:14<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00941713-c3a2-4d27-81dc-cd447ace4a47,50.21326246626034\n",
      "00aea02f-a95a-4c04-8be3-777461732cdf,58.99425420019716\n",
      "04fdb619-d902-4e98-a5e9-a8198bfe047c,70.82884758714319\n",
      "05029661-f8d8-441b-9cab-3c79f28a8b26,64.2093810359247\n",
      "059a146e-a37c-498f-8c0b-5a78204249cb,45.1784109814664\n",
      "06376869-829c-45db-b362-721060d01e3f,57.265305851156576\n",
      "0a8f26c5-8fa3-4cfc-aeaa-d1dab54cd0c6,57.14192271103594\n",
      "0dd38dd7-3351-492b-9eb2-a3c8dc411251,71.3147282977284\n",
      "0eab330b-8cf3-40d9-809b-644362365461,61.73190993753535\n",
      "1423aa97-d790-4497-9c24-a35507f07cf9,65.30154823908924\n",
      "1426ed54-fc38-4c44-86c6-c822c71db4cd,53.20619741850841\n",
      "14b4fe36-dcb4-4e35-984f-18d8b9c75f94,87.91773620644501\n",
      "15fa30b7-606f-458d-ab88-8fb49ff0067d,68.01893501552145\n",
      "16055384-9b2c-414e-bcae-a625624351c2,78.92528521109233\n",
      "17842a8d-6619-4dd5-8243-62024dba9107,59.74887898449987\n",
      "1850920c-259d-4651-9cde-132de594c92a,68.72611628217815\n",
      "1eca992a-5b86-4363-9826-c111d9959ac0,67.03260078513611\n",
      "1ed39041-c2bb-4c6c-80d2-7b8db55269a6,75.64684726542603\n",
      "1f8a54f4-a69a-4c13-8461-df7245d96458,78.30197731755632\n",
      "20648965-b793-43fd-99ce-cba14f5a6aed,51.68159854058023\n",
      "2282aa6f-c0d6-4049-966a-21e314b0f645,62.62155766208011\n",
      "228aa747-23df-4234-b9eb-95f2e4fb05c1,60.29296835523452\n",
      "23c825df-7a7e-468d-a1f2-3d689fb80b74,68.03489481768285\n",
      "264c75ff-7f38-4a5a-8255-490a70ca6464,64.71011811654213\n",
      "26daf937-cd62-4970-8b65-e79742bd0f6d,69.07758379584223\n",
      "270c16aa-90ba-465f-8bca-cf1f7e53afae,62.010296246801026\n",
      "28448b40-8b55-492a-998c-398b6938ac94,88.36276227808311\n",
      "2ac925a2-a9cb-4095-a049-829f700e97c0,67.80579553394801\n",
      "2b1cd01c-7831-4513-b47e-31fba75ac1f4,51.39358777522413\n",
      "2e4be39f-bd6c-4955-8a35-60e77b602fb0,70.72297167618241\n",
      "2ed25b36-81c4-41a4-a640-876d3974d4b3,80.73109588043992\n",
      "304cfd5f-fbcb-474c-b970-529969bb4bd5,77.07632127470787\n",
      "31d2d652-cb18-474c-bde7-4ffc7a4776f3,62.91057736183002\n",
      "324459b6-236b-435b-9c1d-3b6886739beb,55.03998998325416\n",
      "3280d318-0100-41e2-bb14-c6742eb9757e,58.66073531071125\n",
      "33b296fa-dbfc-4c21-8af4-f5c46b38ea50,61.72016721529033\n",
      "34d6ce08-90be-40ed-af5b-6a99af8d4ac1,60.084528534428415\n",
      "37ddc7fd-e770-42b4-8b68-f3e48bf07f75,53.39170257774606\n",
      "3d326ac3-8f87-47d1-be1d-8f4d710a7761,59.684679038783266\n",
      "3d7fcb75-1d7b-4d98-8d00-1b623b7860cb,35.73351668851213\n",
      "3d9555b3-a849-47d7-823d-b11e0a15feeb,71.94157274060771\n",
      "3dffa192-5a2b-47dd-bcd4-17294875c60d,68.85742874814726\n",
      "3fdb8db8-0a7f-44cb-bb8f-107bfb91ee0c,65.90442965210737\n",
      "409034a0-423c-4768-ad93-56fc8c1805b7,73.21727788019561\n",
      "4240de8d-5514-47d0-9d9f-1b44810c0ae6,59.96060528454368\n",
      "42df1634-3d90-4078-b9c7-29ae15b42a45,63.975320046181395\n",
      "43563575-539e-4631-827f-957fe632e5f2,66.69618388946206\n",
      "45c51719-4a5a-4e7a-b3c4-e0d0146430e8,43.67114933272266\n",
      "47cb8f57-e395-496a-92ba-12871a697115,67.71920451817753\n",
      "49a06c67-e05a-4017-82bf-2d0a14857607,55.16953095258567\n",
      "4a1edd99-269d-4efc-ac18-2330f8810809,59.76471922453162\n",
      "4d4d84c0-4e68-4032-82af-a07cbf674c01,78.52266581754688\n",
      "505215e5-2e8d-44cc-8cf7-aab2612d0af7,68.21826053532132\n",
      "50ad8767-3a74-40be-945a-d147b62e91ee,70.44122977319073\n",
      "51b5f862-9850-4bc0-9829-b9fd4cf4fd1c,57.5544298136968\n",
      "51d45da2-e282-4e82-92e1-105adfa121a3,75.9048478054907\n",
      "5365936a-bc23-4568-85d7-347cc8613977,80.98299418086991\n",
      "548d4460-0827-48d6-b82a-ccdcc6baad8f,79.8555112912773\n",
      "57284543-ea53-4a3a-a442-809bbe57d813,85.93638113540719\n",
      "57aee6ab-a690-4baf-a112-e94be29c3f82,73.34378148862729\n",
      "57f25380-afb9-427f-8235-7e17b5f957c8,56.752146241462775\n",
      "58f661be-a5e2-4470-af89-09a886b73f71,58.482111833190835\n",
      "5fdaac55-222b-40ae-b52a-6246f845c017,62.67037483473307\n",
      "60cd5b4d-fd0d-47c5-ba5f-d32471e5df2e,67.15057016756317\n",
      "60ea55cd-85a7-4eeb-9136-4a55f2b4a633,68.25462443959908\n",
      "6403f70d-e140-4c33-9ffe-a8e2a7e7d21c,62.336373358932434\n",
      "65af5b73-5b22-438c-b51f-6ac36871fd8a,60.72201596268297\n",
      "660eb811-0f28-415f-9fe0-28a95a4a7792,65.95935819238082\n",
      "683d30d0-7ab7-4301-8220-7650e69aa6d8,58.27580756355312\n",
      "697db925-f4dc-4f27-be02-d5c362ea5252,69.41582945623051\n",
      "6ab3cb6b-1ca1-4baf-9c3c-4cefc33af26a,81.34517489586116\n",
      "6e7c1182-4dbd-4d9f-976f-76b0f4b49061,66.93474359204521\n",
      "6fe01a52-bde2-4e92-95f1-9190eaa24c21,58.58660089835499\n",
      "7106267c-34d8-4fc0-b1c6-4da62334d65f,65.5354515297797\n",
      "715683ee-44fd-4916-89b6-d2e342976040,58.859975092406614\n",
      "7175ae56-71cb-4de3-adba-98ab69b257a4,72.45471674137531\n",
      "747de66d-104e-41a2-94a4-2520bd4f9246,66.36720452967482\n",
      "75bf204d-988a-4e0a-bbaf-864b883a8cac,63.27872853360744\n",
      "777f9bd2-7d06-4e7f-a9f6-a5017ce84cd4,72.76614413501747\n",
      "783ba178-b89c-4ea2-a0d3-6792d9d38ad6,74.34291246877653\n",
      "7848e8aa-1069-460e-b416-28acfc7b6046,57.071356768994264\n",
      "79174808-0dbb-4ab2-a5ef-67fef2322a87,73.77800508218083\n",
      "79e5a453-6532-42db-a0ae-c9a3c81e6a1f,55.63985023035953\n",
      "7ad45e74-d1d0-4968-9118-0aaf76fe292f,56.086869367158535\n",
      "7b39f5d0-bbcb-4094-9794-b3b460ac0f69,61.96623614849397\n",
      "7b432745-5823-4232-a760-b40fbe31746c,65.02686773530807\n",
      "7c1d06ee-3f0f-42b7-afbc-2860c79ae3c2,66.58425920717553\n",
      "7d001379-da52-4a65-a157-679338418315,57.02939749409373\n",
      "7d0b05e0-bf4a-4a7e-a4e3-7003f075479e,50.55623192797679\n",
      "7ebbfd9c-ecbc-4907-84d6-3a897bdff09a,55.445683934453776\n",
      "7f7ea0b2-a4df-45c3-9d52-0706c00e4aff,49.07027814885634\n",
      "806deaa1-0d37-4621-960d-973bf3318782,60.50618669827098\n",
      "80e0286f-5674-4a52-9b28-827ba6615d78,77.77934731870369\n",
      "8111aefa-053c-42d8-94d8-8da5e6e56f07,56.28865486725561\n",
      "81312743-f11d-4adf-950d-30d15ab0e127,85.93438045967315\n",
      "8216db1e-f511-4a73-b2b9-f8ad42b79715,62.74241010201854\n",
      "8340a645-914b-409b-b151-47a9b2ed6001,65.30304923989027\n",
      "851b8beb-1533-4151-b636-ba29bc70edff,63.74100362862708\n",
      "8585296b-8843-4233-ae26-99082dc65f1e,85.92427743914064\n",
      "85ca2c6b-9002-4333-ae3b-bb6452254878,88.0226237811669\n",
      "879d1e96-8432-4ece-8aaf-57a3c4a5ed6a,70.95779285171685\n",
      "88c52225-4a64-438a-8736-baf061d2db59,83.10708477973154\n",
      "8938e6c1-b773-4436-b6aa-e8d4ece7b8fd,46.285539951720004\n",
      "89cb660b-ffcd-40bf-916d-0aa44a590721,84.91959455425054\n",
      "8d4cb56f-58f2-4f63-ad77-c10cbe31ffe7,55.44228454968408\n",
      "8f5d03b7-03df-4cfe-9413-fae54264af76,66.46154468970485\n",
      "91dd409e-95bc-4621-b16e-a5394a920146,90.63337952047152\n",
      "91fb0d11-b1e3-40ad-93b1-ddec7e1f53f5,58.6152704929573\n",
      "930557c6-96ae-46ef-981e-0b44b5eaaf74,70.26090757467928\n",
      "95b5c66b-517a-4c97-a5d2-c6924f903f61,54.36137846853686\n",
      "99c88c56-9091-4512-8167-0e553f17d38d,64.1089226914772\n",
      "9a3f2930-d7f2-4d76-8bfb-2e27f0cd54b7,78.65100509480133\n",
      "9b990127-5af1-46c2-a30e-c93481619e55,69.82168221647329\n",
      "9c46b412-33ab-4f6d-806f-cd831647da74,46.90997641083875\n",
      "9c8184f8-6beb-44fd-9a0b-e83134e4891c,66.41416684140536\n",
      "9e42f4e9-fe8e-44be-b002-0af7dd830278,71.78821442026597\n",
      "a3001cc1-cc8a-4771-98db-b27617293ce6,58.77491167664131\n",
      "a384ecae-4cac-4ec4-9886-3d2094ca61ba,75.2690379760088\n",
      "a44087da-1c37-4a5f-a825-5518f7f11010,49.66838311761306\n",
      "a49a5587-97c3-4b90-9374-4d0023079904,89.09688889771728\n",
      "a6884d1c-1630-4b81-bfac-8ca6432501c2,70.12217562172494\n",
      "a805d56f-26cb-49d2-8a8c-410df0981829,52.82203985166893\n",
      "a8693864-af3d-4f7c-8825-5b7215d7a314,35.30922586940176\n",
      "a8973ed0-2564-41ac-ab9d-a6a470b183db,54.6329339961913\n",
      "aabccc64-2c35-44df-8531-56988ab6c88c,68.14032601114977\n",
      "ae295f3a-f18b-46ba-a781-951e50d9fbad,61.74085274654756\n",
      "b07e687a-c651-4ba8-bee8-43c889bc8782,50.002272279386865\n",
      "b2fca34d-ce23-46be-8399-0df046131f4b,64.80202031821564\n",
      "b4308b75-cef9-45f9-b94b-ebb6c8639086,77.48868252262773\n",
      "b4595ad8-eafc-415c-a72e-2f5f9ac51021,72.90400227780498\n",
      "b4fed49e-ca43-4c31-af94-025e798cf7e0,75.58568030976551\n",
      "b5299dc8-ab52-43ee-b481-72e6d5271bb3,83.42379516612726\n",
      "b73f91f8-732f-4a48-bcbd-eadbbb457a94,96.21560661359946\n",
      "b7bd59e9-fddf-439c-b5f6-4721e34f1e65,55.863077234097055\n",
      "b80f1f4d-95ea-426f-b72a-32ae496ccfc6,57.93656963668041\n",
      "b93e97d0-a5c0-465e-851a-0eebaacb218e,61.65308878808517\n",
      "bbd9e432-27b8-4000-ac82-47c439c44805,56.55249213242674\n",
      "be91f103-c7de-4e40-ae12-12d3799ea470,70.2356581088585\n",
      "c5c72adc-78af-4dde-9e82-4235d485d269,56.59225304759284\n",
      "c5f323f7-8cc2-43e3-abcf-e58c96c4b2b6,66.7960415192149\n",
      "c6bf6cb6-0e27-49c2-be99-c0f03ec1f9b1,54.573855502022056\n",
      "c74c8b5d-0786-4f5e-a621-61a98ac876ca,41.12053365585165\n",
      "c8f485e3-5799-498f-ab80-4737e6b8f11a,68.4667592954459\n",
      "ca067a8b-2e97-4261-ae9b-abc46f53e984,61.16006009832167\n",
      "ca1aaa00-2229-4ee8-b153-232e9b69863e,63.081600688519416\n",
      "cb1e5dc5-f252-4159-99d7-fed437bb2032,59.49574551464028\n",
      "cc5c751c-3cc6-44b1-924e-b01a7e7d93eb,85.60237961052438\n",
      "cd7306fa-0bf1-4272-9e04-3844a98c7c24,64.23763876268147\n",
      "ce708d18-5546-4f4d-828b-1dc860431583,63.171454911496475\n",
      "ce811f98-6f05-454e-a6dc-f460309e2cb6,68.42703785210607\n",
      "d181a524-20ec-4f88-ad94-c7f8a189fe3d,76.66447151710727\n",
      "d44bb85a-5fc0-4488-8add-211159f43100,74.30432998539428\n",
      "d4e08bc3-9184-49d7-a2c1-426ec3392022,58.96606898425491\n",
      "d715a367-da27-4b4c-aa42-74f8d09b0c0d,56.71499312501889\n",
      "d89b766d-6478-4b4b-9104-150370cb3991,67.83961804237502\n",
      "dcdc77e8-44ce-48e6-be03-35b5c604af83,80.44890203021083\n",
      "dd093288-f6a9-4f84-a875-1af769e4398c,63.873801294708414\n",
      "df60d9d3-e52a-4df8-a23c-19a1ed18342a,91.93163704251315\n",
      "dff11cd3-7072-4820-8093-79ea79f0ac00,61.98051287343732\n",
      "e0021863-3340-4136-9e7f-bf894d610a1d,57.601309412513366\n",
      "e091fb08-d576-4fdb-b355-301d747080b1,77.47222743422138\n",
      "e2011bf5-3520-404d-9df0-1cf38d56d689,70.94240842523271\n",
      "e206e096-762b-4aef-a4b4-020b7815732a,66.15557848803816\n",
      "e34f91d6-bb89-41a6-8b04-5b143d65bcb9,75.08591116620782\n",
      "e44ea1c5-3a41-412c-af16-186988e8838b,65.40873290558605\n",
      "e4f0b779-800f-435f-a21c-31f345ac9eed,81.99692969945411\n",
      "e6e27dda-15d1-4da1-b423-caa6af87a9bd,34.52819405739126\n",
      "e7091a29-62b6-4c86-a89e-c86b54093d11,68.53735776786792\n",
      "e75ac493-a8de-4854-97e3-e517230b0ab6,95.88206908109663\n",
      "e7659e60-6d80-4422-ad64-ca60a6176d9a,69.07759305231666\n",
      "eb0db341-105c-442b-a056-737cfd096cfd,66.62858756977187\n",
      "ec0e5e18-6fa7-4236-bdb7-6fdb656f8e2c,53.735125767148844\n",
      "ed028e23-699b-4732-81ff-fd76bfa005f6,46.702900349552365\n",
      "edb56191-949f-4c2e-a9b6-fe88d10587a2,51.16891424655832\n",
      "eddb5637-e477-4fc8-8b09-74eddb27b2fe,71.50215975299734\n",
      "ef3a256d-db00-40ff-a8e3-565c44a17452,62.128184620187376\n",
      "efedf04c-b749-40be-812b-03832cd7d9bd,62.9272679883165\n",
      "f28cbaba-6e20-4911-aede-2480e65d2333,64.55625488115656\n",
      "f324d9d7-07ca-4800-a04c-b72f1c200e34,62.24569106667992\n",
      "f38fbedc-6417-494f-bf9f-4c72087e7293,65.57753749591872\n",
      "f4489266-4783-4be3-9ea1-4137c8093646,102.73643875240904\n",
      "f5111c86-dc70-477e-92f0-1e8efecf47d4,44.57976978244073\n",
      "f9534a6b-e75b-4540-a86c-fa17494849e9,60.70533562048973\n",
      "fab774ac-38c8-4d86-910c-7ad0fa8470c5,64.27493037106366\n",
      "fac3042d-d72d-43a7-9170-a424e3061fac,58.811284834102274\n",
      "fbf473eb-ea6f-4a4a-b2d8-405bc09f9850,59.832431513232635\n",
      "fccd270d-63f8-42b6-b73e-13f6d3e5f612,67.62581229980266\n",
      "fe81cca3-d9c2-4d82-97a4-9cc1444ea219,70.63982302354212\n"
     ]
    }
   ],
   "source": [
    "#### BONUS PART:\n",
    "bonus_data_path = \"data/bonus/*.html\"\n",
    "\n",
    "bonus_code2convos = dict()\n",
    "\n",
    "pbar = tqdm.tqdm(sorted(list(glob(bonus_data_path))))\n",
    "for path in pbar:\n",
    "    # print(Path.cwd() / path)\n",
    "    file_code = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "            \n",
    "        # get the file id to use it as key later on\n",
    "        fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "        # read the html file\n",
    "        html_page = fh.read()\n",
    "\n",
    "        # parse the html file with bs4 so we can extract needed stuff\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        # grab the conversations with the data-testid pattern\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "        convo_texts = []\n",
    "\n",
    "        for i, convo in enumerate(conversations):\n",
    "            convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "            if len(convo) > 0:\n",
    "                role = convo[0].get(\"data-message-author-role\")\n",
    "                convo_texts.append({\n",
    "                        \"role\" : role,\n",
    "                        \"text\" : convo[0].text\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        bonus_code2convos[file_code] = convo_texts\n",
    "\n",
    "prompts = []\n",
    "answers = []\n",
    "bonus_code2prompts = dict()\n",
    "code2answers = defaultdict(list)\n",
    "for code , convos in bonus_code2convos.items():\n",
    "    user_prompts = []\n",
    "    for conv in convos:\n",
    "        if conv[\"role\"] == \"user\":\n",
    "            prompts.append(conv[\"text\"].lower())\n",
    "            user_prompts.append(conv[\"text\"].lower()) # Adding the lower case version of the prompt\n",
    "        else:\n",
    "            answers.append(conv[\"text\"].lower())\n",
    "            code2answers[code].append(conv[\"text\"].lower()) # Adding the lower case version of the answer\n",
    "\n",
    "    bonus_code2prompts[code] = user_prompts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### predicting scores from prompts:\n",
    "    \n",
    "for code, prompts in bonus_code2prompts.items():\n",
    "    predicted_score = ta.predict_grades_for_multiple_prompts(code, prompts)\n",
    "    if(predicted_score != -1):\n",
    "        print(code+\",\"+str(predicted_score))\n",
    "    else:\n",
    "        print(code+\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
